{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target rate of the train set is 35.66%\n",
      "The target rate of the validation set is 27.23%\n",
      "The target rate of the test set is 31.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desho\\AppData\\Local\\Temp\\ipykernel_62940\\2423259785.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  clickbait = pd.read_table(\"C:\\\\Users\\\\Desho\\\\OneDrive - Illinois Institute of Technology\\\\Documents\\\\School IIT\\\\Fall 2023\\\\CS 585 Natural Language Processing\\\\HomeWorks\\\\HomeWork2\\\\clickbait.txt\", header=None, sep='delimiter')\n",
      "C:\\Users\\Desho\\AppData\\Local\\Temp\\ipykernel_62940\\2423259785.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  nonclickbait = pd.read_table(\"C:\\\\Users\\\\Desho\\\\OneDrive - Illinois Institute of Technology\\\\Documents\\\\School IIT\\\\Fall 2023\\\\CS 585 Natural Language Processing\\\\HomeWorks\\\\HomeWork2\\\\not-clickbait.txt\", header=None, sep='delimiter')\n",
      "c:\\Users\\Desho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Phase 1 – Reading the data\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    " \n",
    "           \n",
    "clickbait = pd.read_table(\" \", header=None, sep='delimiter') # Clickbait file directory \n",
    "nonclickbait = pd.read_table(\" \", header=None, sep='delimiter')  # non Clickbait file directory\n",
    "\n",
    "\n",
    "clickbait['label'] = 1\n",
    "nonclickbait['label'] = 0 \n",
    "\n",
    "clickbait_df = pd.concat([clickbait, nonclickbait], ignore_index=True)\n",
    "clickbait_df = clickbait_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_set, val_set, test_set = np.split(clickbait_df, [int(0.72*len(clickbait_df)), int(0.8*len(clickbait_df))])\n",
    "\n",
    "trainclickbait_target_rate = train_set['label'].mean() * 100\n",
    "valclickbait_target_rate = val_set['label'].mean() * 100\n",
    "testclickbait_target_rate = test_set['label'].mean() * 100\n",
    "\n",
    "print(f\"The target rate of the train set is {trainclickbait_target_rate:.2f}%\")\n",
    "print(f\"The target rate of the validation set is {valclickbait_target_rate:.2f}%\")\n",
    "print(f\"The target rate of the test set is {testclickbait_target_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training set metrics for pos_label =1 for clickbait:\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "\n",
      " Validation set metrics pos_label =1 for clickbait:\n",
      "Precision: 0.94\n",
      "Recall: 0.90\n",
      "F1 Score: 0.92\n",
      " \n",
      " Training set metrics for pos_label =0 for non clickbait:\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "\n",
      " Validation set metrics pos_label =0 for non clickbait:\n",
      "Precision: 0.96\n",
      "Recall: 0.98\n",
      "F1 Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "#Phase 2 - Training a single Bag-of-Words (BOW) Text Classifier \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "clickbait_pipeline =Pipeline ([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "x_train_set = train_set[0]\n",
    "y_train_set = train_set['label']\n",
    "\n",
    "x_val_set = val_set[0]\n",
    "y_val_set = val_set['label']\n",
    "\n",
    "\n",
    "clickbait_pipeline.fit(x_train_set,y_train_set)\n",
    "\n",
    "y_pred_clickbait_train =  clickbait_pipeline.predict(x_train_set)\n",
    "y_pred_clickbait_val =clickbait_pipeline.predict(x_val_set)\n",
    "\n",
    "\n",
    "precision_train_set_1 =precision_score(y_train_set, y_pred_clickbait_train, pos_label=1)\n",
    "recall_train_set_1 =recall_score(y_train_set, y_pred_clickbait_train, pos_label=1)\n",
    "f1_train_set_1 =f1_score(y_train_set, y_pred_clickbait_train, pos_label=1)\n",
    "\n",
    "\n",
    "precision_val_set_1 =precision_score(y_val_set, y_pred_clickbait_val, pos_label=1)\n",
    "recall_val_set_1 =recall_score(y_val_set, y_pred_clickbait_val, pos_label=1)\n",
    "f1_val_set_1 =f1_score(y_val_set, y_pred_clickbait_val, pos_label=1)\n",
    "\n",
    "\n",
    "print(\" Training set metrics for pos_label =1 for clickbait:\")\n",
    "print(f\"Precision: {precision_train_set_1:.2f}\")\n",
    "print(f\"Recall: {recall_train_set_1:.2f}\")\n",
    "print(f\"F1 Score: {f1_train_set_1:.2f}\")\n",
    "\n",
    "print(\"\\n Validation set metrics pos_label =1 for clickbait:\")\n",
    "print(f\"Precision: {precision_val_set_1:.2f}\")\n",
    "print(f\"Recall: {recall_val_set_1:.2f}\")\n",
    "print(f\"F1 Score: {f1_val_set_1:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "precision_train_set_0 =precision_score(y_train_set, y_pred_clickbait_train, pos_label=0)\n",
    "recall_train_set_0 =recall_score(y_train_set, y_pred_clickbait_train, pos_label=0)\n",
    "f1_train_set_0 =f1_score(y_train_set, y_pred_clickbait_train, pos_label=0)\n",
    "\n",
    "\n",
    "precision_val_set_0 =precision_score(y_val_set, y_pred_clickbait_val, pos_label=0)\n",
    "recall_val_set_0 =recall_score(y_val_set, y_pred_clickbait_val, pos_label=0)\n",
    "f1_val_set_0 =f1_score(y_val_set, y_pred_clickbait_val, pos_label=0)\n",
    "\n",
    "print(\" \\n Training set metrics for pos_label =0 for non clickbait:\")\n",
    "print(f\"Precision: {precision_train_set_0:.2f}\")\n",
    "print(f\"Recall: {recall_train_set_0:.2f}\")\n",
    "print(f\"F1 Score: {f1_train_set_0:.2f}\")\n",
    "\n",
    "print(\"\\n Validation set metrics pos_label =0 for non clickbait:\")\n",
    "print(f\"Precision: {precision_val_set_0:.2f}\")\n",
    "print(f\"Recall: {recall_val_set_0:.2f}\")\n",
    "print(f\"F1 Score: {f1_val_set_0:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_label =1 for clickbait\n",
      "Parameters: {'clf__alpha': 2.0, 'vect__max_df': 1.0, 'vect__ngram_range': (1, 2)}\n",
      "Precision: 0.96\n",
      "Recall: 0.88\n",
      "F1 Score: 0.92\n",
      "\n",
      "pos_label =0 for non clickbait\n",
      "Parameters: {'clf__alpha': 2.0, 'vect__max_df': 1.0, 'vect__ngram_range': (1, 2)}\n",
      "Precision: 0.96\n",
      "Recall: 0.99\n",
      "F1 Score: 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Phase 3 - Hyperparameter Tuning\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "clickbait_pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clickbait_param_grid =  {\n",
    "    'vect__max_df' : [0.25, 0.5, 0.75,0.80, 1.0],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0,1.5, 2.0],\n",
    "    'vect__ngram_range': [(1,1),(1,2)]\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(clickbait_param_grid)\n",
    "\n",
    "results = []\n",
    "for params in grid:\n",
    "    clickbait_pipeline2.set_params(**params)\n",
    "    \n",
    "    clickbait_pipeline2.fit(x_train_set,y_train_set)\n",
    "\n",
    "y_pred_clickbait_train2 =  clickbait_pipeline2.predict(x_train_set)\n",
    "y_pred_clickbait_val2 =clickbait_pipeline2.predict(x_val_set)\n",
    "    \n",
    "results_0 = []\n",
    "for params in grid:\n",
    "    clickbait_pipeline2.set_params(**params)\n",
    "    \n",
    "    clickbait_pipeline2.fit(x_train_set,y_train_set)\n",
    "\n",
    "y_pred_clickbait_train2 =  clickbait_pipeline2.predict(x_train_set)\n",
    "y_pred_clickbait_val2 =clickbait_pipeline2.predict(x_val_set)\n",
    "    \n",
    "    \n",
    "new_precision_val_set_1 =precision_score(y_val_set, y_pred_clickbait_val2, pos_label=1)\n",
    "new_recall_val_set_1 =recall_score(y_val_set, y_pred_clickbait_val2, pos_label=1)\n",
    "new_f1_val_set_1 =f1_score(y_val_set, y_pred_clickbait_val2, pos_label=1)\n",
    "\n",
    "new_precision_val_set_0 =precision_score(y_val_set, y_pred_clickbait_val2, pos_label=0)\n",
    "new_recall_val_set_0 =recall_score(y_val_set, y_pred_clickbait_val2, pos_label=0)\n",
    "new_f1_val_set_0 =f1_score(y_val_set, y_pred_clickbait_val2, pos_label=0)\n",
    "\n",
    "results.append({\n",
    "    \n",
    "    'params': params,\n",
    "        'precision': new_precision_val_set_1,\n",
    "        'recall': new_recall_val_set_1,\n",
    "        'f1': new_f1_val_set_1\n",
    "        \n",
    "    \n",
    "    \n",
    "})\n",
    "\n",
    "results_0.append({\n",
    "    'params': params,\n",
    "        'params': params,\n",
    "        'precision': new_precision_val_set_0,\n",
    "        'recall': new_recall_val_set_0,\n",
    "        'f1': new_f1_val_set_0\n",
    "    \n",
    "    \n",
    "})\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "results = sorted(results, key=lambda x: x['f1'], reverse=True)\n",
    "for result in results:\n",
    "    print(\"pos_label =1 for clickbait\")\n",
    "    print(f\"Parameters: {result['params']}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1']:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "results_0 = sorted(results_0, key=lambda x: x['f1'], reverse=True)\n",
    "for result in results_0:\n",
    "    print(\"pos_label =0 for non clickbait\")\n",
    "    print(f\"Parameters: {result['params']}\")\n",
    "    print(f\"Precision: {result['precision']:.2f}\")\n",
    "    print(f\"Recall: {result['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {result['f1']:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set metrics:\n",
      "Precision: 0.86\n",
      "Recall: 0.84\n",
      "F1 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Phase 4 - Model selection\n",
    "\n",
    "x_test_set = test_set[0]\n",
    "y_test_set = test_set['label']\n",
    "\n",
    "\n",
    "clickbait_pipeline2.fit(x_train_set,y_train_set)\n",
    "\n",
    "y_pred_clickbait_test =  clickbait_pipeline2.predict(x_test_set)\n",
    "\n",
    "precision_test_set =precision_score(y_test_set, y_pred_clickbait_test, pos_label=1)\n",
    "recall_test_set =recall_score(y_test_set, y_pred_clickbait_test, pos_label=1)\n",
    "f1_test_set =f1_score(y_test_set, y_pred_clickbait_test, pos_label=1)\n",
    "\n",
    "print(\"Test set metrics:\")\n",
    "print(f\"Precision: {precision_test_set:.2f}\")\n",
    "print(f\"Recall: {recall_test_set:.2f}\")\n",
    "print(f\"F1 Score: {f1_test_set:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 clickbait indicators:\n",
      "the (log-probability: -4.78)\n",
      "you (log-probability: -5.32)\n",
      "to (log-probability: -5.37)\n",
      "this (log-probability: -5.45)\n",
      "is (log-probability: -5.50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Phase 5 - – Key Indicators\n",
    "\n",
    "log_prob_best_pipeline = clickbait_pipeline.named_steps['clf'].feature_log_prob_[1, :]\n",
    "\n",
    "best_pipeline_feature_names = clickbait_pipeline.named_steps['vect'].get_feature_names_out()\n",
    "\n",
    "best_sorted_features = sorted(zip(log_prob_best_pipeline, best_pipeline_feature_names), reverse=True)\n",
    "\n",
    "print(\"Top 5 clickbait indicators:\")\n",
    "for prob, feat in best_sorted_features[:5]:\n",
    "    print(f\"{feat} (log-probability: {prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.42\n",
      "Recall: 0.68\n"
     ]
    }
   ],
   "source": [
    "  # Phase 6 - Regular expressions\n",
    "import re\n",
    "\n",
    "keywords = []\n",
    "\n",
    "for prob, feat in best_sorted_features[:5]:\n",
    "    keywords.append(feat)\n",
    "\n",
    "\n",
    "pattern = r'\\b(?:' + '|'.join(keywords) + r')\\b'\n",
    "\n",
    "regex = re.compile(pattern, re.IGNORECASE)\n",
    "\n",
    "def check_clickbait(x_test_set):\n",
    "     match = re.search(regex,x_test_set)\n",
    "     return bool(match)\n",
    "     \n",
    "     \n",
    "\n",
    "\n",
    "predictions = [check_clickbait(text) for text in x_test_set]\n",
    "predictions = [int(pred) for pred in predictions]\n",
    "\n",
    "precision = precision_score(y_test_set, predictions)\n",
    "recall = recall_score(y_test_set, predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
